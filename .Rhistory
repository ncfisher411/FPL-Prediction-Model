name <- colnames(seven)[i]
mean <- mean(seven[, i])
sd <- sd(seven[, i])
seven[, i] <- round((seven[, i]-mean)/sd,2)
colnames(seven)[i] <- paste(colnames(seven)[i],"z-score",sep="_")
}
eight <- two
for(i in 7:77) {
name <- colnames(eight)[i]
mean <- mean(eight[, i])
sd <- sd(eight[, i])
eight[, i] <- round((eight[, i]-mean)/sd,2)
colnames(eight)[i] <- paste(colnames(eight)[i],"z-score",sep="_")
}
nine <- three
for(i in 7:69) {
name <- colnames(nine)[i]
mean <- mean(nine[, i])
sd <- sd(nine[, i])
nine[, i] <- round((nine[, i]-mean)/sd,2)
colnames(nine)[i] <- paste(colnames(nine)[i],"z-score",sep="_")
}
ten <- four
for(i in 7:81) {
name <- colnames(ten)[i]
mean <- mean(ten[, i])
sd <- sd(ten[, i])
ten[, i] <- round((ten[, i]-mean)/sd,2)
colnames(ten)[i] <- paste(colnames(ten)[i],"z-score",sep="_")
}
xl_list <- list("overall"=five, "fwd"=one, "mid"=two, "def"=three, "gkp"=four,
"fwd_z-score"=seven, "mid_z-score"=eight, "def_z-score"=nine,
"gkp_z-score"=ten)
write.xlsx(xl_list, file = "final_prediction.xlsx")
## Place some exploratory plots for the results
### Positions that are most valuable based on predicted points, value index
temp <- five %>% select(Position, Predicted_Points) %>% group_by(Position) %>%
summarize(Predicted_Points=mean(Predicted_Points, na.rm=T)) %>%
ungroup() %>%
pivot_longer(!Position, names_to = "Stat", values_to = "Value") %>%
mutate(Value=round(Value,1))
one <- ggplot(temp, aes(x=Stat, y=Value, fill=Position)) +
geom_col(position=position_dodge(width=0.9)) +
geom_text(aes(x=Stat, y=Value, label=Value),
position = position_dodge(width=0.9), vjust=-.5) +
ggtitle("Predicted Points by Position")
one
temp <- five %>% group_by(Team) %>%
summarize(Predicted_Points=mean(Predicted_Points)) %>%
mutate(Rank=rank(-Predicted_Points)) %>%
mutate(d=percent_rank(Predicted_Points)) %>%
mutate(Quantile=ifelse(d<0.26,4,NA)) %>%
mutate(Quantile=ifelse(d>0.25,3,Quantile)) %>%
mutate(Quantile=ifelse(d>0.5,2,Quantile)) %>%
mutate(Quantile=ifelse(d>0.75,1,Quantile))
one <- ggplot(temp, aes(x=Rank, y=Predicted_Points, colour=factor(Quantile), label=Team)) +
geom_point(alpha=0, aes(color=factor(Quantile))) +
geom_text(aes(color=factor(Quantile)), size=3) +
#coord_cartesian(clip="off") +
ggtitle("Average Predicted Points by Team")
one
library(broom)
set.seed(123)
fwd <- trends %>% ungroup() %>% filter(Position=="FWD") %>%
select(all_of(c("Player", "Points")), all_of(f_rows)) %>%
mutate_all(~ ifelse(is.na(.),0,.))
train_index <- sample(1:nrow(fwd), nrow(fwd) * 0.8)
train_data <- fwd[train_index, ]
x_train <- train_data %>% select(-c("Player", "Points"))
y_train <- train_data %>% select(Points) %>% data.matrix()
test_data <- fwd[-train_index, ]
x_test <- test_data %>% select(-c("Player", "Points")) %>% data.matrix()
y_test <- test_data %>% select(Points) %>% data.matrix()
#dim(train_data)
#dim(test_data)
ridge_model <- glmnet(x_train, y_train, alpha=0, lambda = lambda)
temp <- tidy(ridge_model)
kbl(temp) %>% kable_classic(full_width=T, html_font = "Arial")
x_train <- x_train %>% data.matrix()
temp <- train_data %>% select(Player, Points)
one <- predict(ridge_model, newx = x_train) %>% data.frame() %>%
rename(Predicted=1) %>% cbind(temp) %>%
mutate(Points=log(Points)) %>%
mutate(Predicted=log(Predicted)) %>%
select(Player, Points, Predicted) %>%
arrange(Player) %>%
mutate(row=row_number())
temp <- test_data %>% select(Player, Points)
two <- predict(ridge_model, newx = x_test) %>% data.frame() %>%
rename(Predicted=1) %>% cbind(temp) %>%
mutate(Points=log(Points)) %>%
mutate(Predicted=log(Predicted)) %>%
arrange(Player) %>%
mutate(row=row_number())
plot <- ggplot(one, aes(x=row, y=Points, color="Observed Point totals")) +
geom_point() +
geom_point(aes(y=Predicted, color="Predicted point totals")) +
geom_smooth(aes(y=Predicted, color="Smoothed best fit - Training")) +
geom_smooth(aes(y=Points, color="Smoothed best fit - Observed")) +
theme(axis.text.x = element_blank(),
legend.title = element_blank()) +
xlab("Player") + ylab(" Log Points") +
ggtitle("Lowess curve: Validation of forwards ridge regression model, Training model")
plot
plot <- ggplot(two, aes(x=row, y=Points, color="Observed Point totals")) +
geom_point() +
geom_point(aes(y=Predicted, color="Predicted point totals")) +
geom_smooth(aes(y=Predicted, color="Smoothed best fit - Training")) +
geom_smooth(aes(y=Points, color="Smoothed best fit - Observed")) +
theme(axis.text.x = element_blank(),
legend.title = element_blank()) +
xlab("Player") + ylab(" Log Points") +
ggtitle("Lowess curve: Validation of forwards ridge regression model, Testing model")
plot
def<- trends %>% ungroup() %>% filter(Position=="DEF") %>%
select(where(~ !is.character(.x))) %>%
mutate_all(~ ifelse(is.na(.),0,.))
points <- def$Points %>% as.matrix()
temp <- trends %>% ungroup() %>% filter(Position=="DEF") %>%
select(-c("Points", "Bonus", "Position")) %>%
mutate_all(~ ifelse(is.na(.),0,.)) %>% data.matrix()
one <- glmnet(temp, points, alpha=0)
five <- cv.glmnet(temp, points, alpha=0)
lambda <- five$lambda.min
set.seed(123)
def <- trends %>% ungroup() %>% filter(Position=="DEF") %>%
select(all_of(c("Player", "Points")), all_of(d_rows)) %>%
mutate_all(~ ifelse(is.na(.),0,.))
train_index <- sample(1:nrow(def), nrow(def) * 0.8)
train_data <- def[train_index, ]
x_train <- train_data %>% select(-c("Player", "Points"))
y_train <- train_data %>% select(Points) %>% data.matrix()
test_data <- def[-train_index, ]
x_test <- test_data %>% select(-c("Player", "Points")) %>% data.matrix()
y_test <- test_data %>% select(Points) %>% data.matrix()
#dim(train_data)
#dim(test_data)
ridge_model <- glmnet(x_train, y_train, alpha=0, lambda = lambda)
temp <- train_data %>% select(Player, Points)
x_train <- x_train %>% data.matrix()
one <- predict(ridge_model, newx = x_train) %>% data.frame() %>%
rename(Predicted=1) %>% cbind(temp) %>%
mutate(Points=log(Points)) %>%
mutate(Predicted=log(Predicted)) %>%
select(Player, Points, Predicted) %>%
arrange(Player) %>%
mutate(row=row_number())
plot <- ggplot(one, aes(x=row, y=Points, color="Observed Point totals")) +
geom_point() +
geom_point(aes(y=Predicted, color="Predicted point totals")) +
geom_smooth(aes(y=Predicted, color="Smoothed best fit - Training")) +
geom_smooth(aes(y=Points, color="Smoothed best fit - Observed")) +
theme(axis.text.x = element_blank(),
legend.title = element_blank()) +
xlab("Player") + ylab("Log Points") +
ggtitle("Lowess curve: Validation of defenders ridge regression model, Training model")
plot
temp <- test_data %>% select(Player, Points)
one <- predict(ridge_model, newx = x_test) %>% data.frame() %>%
rename(Predicted=1) %>% cbind(temp) %>%
mutate(Points=log(Points)) %>%
mutate(Predicted=log(Predicted)) %>%
select(Player, Points, Predicted) %>%
arrange(Player) %>%
mutate(row=row_number())
plot <- ggplot(two, aes(x=row, y=Points, color="Observed Point totals")) +
geom_point() +
geom_point(aes(y=Predicted, color="Predicted point totals")) +
geom_smooth(aes(y=Predicted, color="Smoothed best fit - Testing")) +
geom_smooth(aes(y=Points, color="Smoothed best fit - Observed")) +
theme(axis.text.x = element_blank(),
legend.title = element_blank()) +
xlab("Player") + ylab("Log Points") +
ggtitle("Lowess curve: Validation of defenders ridge regression model, Testing model")
plot
mid <- trends %>% ungroup() %>% filter(Position=="MID") %>%
select(all_of(c("Player", "Points")), all_of(m_rows)) %>%
mutate_all(~ ifelse(is.na(.),0,.))
one <- sample(seq_len(nrow(mid)), size=round(0.8*nrow(mid)), replace = F)
two <- setdiff(seq_len(nrow(mid)), one)
x_train <- mid[one, ] %>% select(-Player)
x_test <- mid[two, ]
temp <- x_test %>% select(Player)
mid_xtest <- x_test %>% select(-Player)
temp <- mid[one, ] %>% data.frame() %>% select(Player, Points)
one <- predict(ols_mid, newdata = x_train) %>% data.frame() %>%
rename(Predicted=1) %>% cbind(temp) %>%
mutate(Points=log(Points)) %>% mutate(Predicted=log(Predicted)) %>%
arrange(Player) %>%
mutate(row=row_number())
plot <- ggplot(one, aes(x=row, y=Points, color="Observed point totals")) +
geom_point() +
geom_point(aes(y=Predicted, color="Predicted point totals")) +
geom_smooth(aes(y=Predicted, color="Smoothed best fit - Training")) +
geom_smooth(aes(y=Points, color="Smoothed best fit - Observed")) +
theme(axis.text.x = element_blank(),
legend.title = element_blank()) +
xlab("Player") + ylab("Log Points") +
ggtitle("Lowess curve: Validation of midfielders OLS regression model, Training model")
plot
temp <- mid[two, ] %>% data.frame() %>% select(Player, Points)
one <- predict(ols_mid, newdata = x_test) %>% data.frame() %>%
rename(Predicted=1) %>% cbind(temp) %>%
mutate(Points=log(Points)) %>% mutate(Predicted=log(Predicted)) %>%
arrange(Player) %>%
mutate(row=row_number())
plot <- ggplot(one, aes(x=row, y=Points, color="Observed point totals")) +
geom_point() +
geom_point(aes(y=Predicted, color="Predicted point totals")) +
geom_smooth(aes(y=Predicted, color="Smoothed best fit - Testing")) +
geom_smooth(aes(y=Points, color="Smoothed best fit - Observed")) +
theme(axis.text.x = element_blank(),
legend.title = element_blank()) +
xlab("Player") + ylab("Log Points") +
ggtitle("Lowess curve: Validation of midfielders OLS regression model, Training model")
plot
set.seed(123)
gk <- trends2 %>% ungroup() %>%
select(all_of(c("Player", "Points")), all_of(gk_rows)) %>%
mutate_all(~ ifelse(is.na(.),0,.))
train_index <- sample(1:nrow(gk), nrow(gk) * 0.8)
train_data <- gk[train_index, ]
x_train <- train_data %>% select(-c("Player"))
y_train <- train_data %>% select(Points) %>% data.matrix()
test_data <- gk[-train_index, ]
x_test <- test_data %>% select(-c("Player")) %>% data.matrix()
y_test <- test_data %>% select(Points) %>% data.matrix()
#dim(train_data)
#dim(test_data)
tr_control <- trainControl(method = "repeatedcv", number = 10, repeats=3, search = "random")
tunegrid <- expand.grid(.mtry=41)
rf_model <- train(Points~., data = x_train, method = "rf", tuneGrid=tunegrid,
trControl=tr_control, importance=T, nodesize=14, ntree=200,
maxnodes=12)
temp <- train_data %>% select(Player, Points)
one <- predict(rf_model, x_train) %>% data.frame() %>%
rename(Predicted=1) %>% cbind(temp) %>%
mutate(Points=log(Points)) %>% mutate(Predicted=log(Predicted)) %>%
arrange(Player) %>%
mutate(row=row_number())
plot <- ggplot(one, aes(x=row, y=Points, color="Observed point totals")) +
geom_point() +
geom_point(aes(y=Predicted, color="Predicted point totals")) +
geom_smooth(aes(y=Predicted, color="Smoothed best fit - Training")) +
geom_smooth(aes(y=Points, color="Smoothed best fit - Observed")) +
theme(axis.text.x = element_blank(),
legend.title = element_blank()) +
xlab("Player") + ylab("Log Points") +
ggtitle("Lowess curve: Validation of goalkeepers random forest model, Training model")
plot
temp <- test_data %>% select(Player, Points)
one <- predict(rf_model, x_test) %>% data.frame() %>%
rename(Predicted=1) %>% cbind(temp) %>%
mutate(Points=log(Points)) %>% mutate(Predicted=log(Predicted)) %>%
arrange(Player) %>%
mutate(row=row_number())
plot <- ggplot(one, aes(x=row, y=Points, color="Observed point totals")) +
geom_point() +
geom_point(aes(y=Predicted, color="Predicted point totals")) +
geom_smooth(aes(y=Predicted, color="Smoothed best fit - Testing")) +
geom_smooth(aes(y=Points, color="Smoothed best fit - Observed")) +
theme(axis.text.x = element_blank(),
legend.title = element_blank()) +
xlab("Player") + ylab("Log Points") +
ggtitle("Lowess curve: Validation of goalkeepers random forest model, Testing model")
plot
library(broom)
set.seed(123)
fwd <- trends %>% ungroup() %>% filter(Position=="FWD") %>%
select(all_of(c("Player", "Points")), all_of(f_rows)) %>%
mutate_all(~ ifelse(is.na(.),0,.))
train_index <- sample(1:nrow(fwd), nrow(fwd) * 0.8)
train_data <- fwd[train_index, ]
x_train <- train_data %>% select(-c("Player", "Points"))
y_train <- train_data %>% select(Points) %>% data.matrix()
test_data <- fwd[-train_index, ]
x_test <- test_data %>% select(-c("Player", "Points")) %>% data.matrix()
y_test <- test_data %>% select(Points) %>% data.matrix()
#dim(train_data)
#dim(test_data)
ridge_model <- glmnet(x_train, y_train, alpha=0, lambda = lambda)
temp <- tidy(ridge_model)
kbl(temp) %>% kable_classic(full_width=T, html_font = "Arial")
x_train <- x_train %>% data.matrix()
temp <- train_data %>% select(Player, Points)
one <- predict(ridge_model, newx = x_train) %>% data.frame() %>%
rename(Predicted=1) %>% cbind(temp) %>%
mutate(Points=log(Points)) %>%
mutate(Predicted=log(Predicted)) %>%
select(Player, Points, Predicted) %>%
arrange(-Points) %>%
mutate(row=row_number())
temp <- test_data %>% select(Player, Points)
two <- predict(ridge_model, newx = x_test) %>% data.frame() %>%
rename(Predicted=1) %>% cbind(temp) %>%
mutate(Points=log(Points)) %>%
mutate(Predicted=log(Predicted)) %>%
arrange(-Points) %>%
mutate(row=row_number())
plot <- ggplot(one, aes(x=row, y=Points, color="Observed Point totals")) +
geom_point() +
geom_point(aes(y=Predicted, color="Predicted point totals")) +
geom_smooth(aes(y=Predicted, color="Smoothed best fit - Training")) +
geom_smooth(aes(y=Points, color="Smoothed best fit - Observed")) +
theme(axis.text.x = element_blank(),
legend.title = element_blank()) +
xlab("Player") + ylab(" Log Points") +
ggtitle("Lowess curve: Validation of forwards ridge regression model, Training model")
plot
plot <- ggplot(two, aes(x=row, y=Points, color="Observed Point totals")) +
geom_point() +
geom_point(aes(y=Predicted, color="Predicted point totals")) +
geom_smooth(aes(y=Predicted, color="Smoothed best fit - Training")) +
geom_smooth(aes(y=Points, color="Smoothed best fit - Observed")) +
theme(axis.text.x = element_blank(),
legend.title = element_blank()) +
xlab("Player") + ylab(" Log Points") +
ggtitle("Lowess curve: Validation of forwards ridge regression model, Testing model")
plot
def<- trends %>% ungroup() %>% filter(Position=="DEF") %>%
select(where(~ !is.character(.x))) %>%
mutate_all(~ ifelse(is.na(.),0,.))
points <- def$Points %>% as.matrix()
temp <- trends %>% ungroup() %>% filter(Position=="DEF") %>%
select(-c("Points", "Bonus", "Position")) %>%
mutate_all(~ ifelse(is.na(.),0,.)) %>% data.matrix()
one <- glmnet(temp, points, alpha=0)
five <- cv.glmnet(temp, points, alpha=0)
lambda <- five$lambda.min
set.seed(123)
def <- trends %>% ungroup() %>% filter(Position=="DEF") %>%
select(all_of(c("Player", "Points")), all_of(d_rows)) %>%
mutate_all(~ ifelse(is.na(.),0,.))
train_index <- sample(1:nrow(def), nrow(def) * 0.8)
train_data <- def[train_index, ]
x_train <- train_data %>% select(-c("Player", "Points"))
y_train <- train_data %>% select(Points) %>% data.matrix()
test_data <- def[-train_index, ]
x_test <- test_data %>% select(-c("Player", "Points")) %>% data.matrix()
y_test <- test_data %>% select(Points) %>% data.matrix()
#dim(train_data)
#dim(test_data)
ridge_model <- glmnet(x_train, y_train, alpha=0, lambda = lambda)
temp <- train_data %>% select(Player, Points)
x_train <- x_train %>% data.matrix()
one <- predict(ridge_model, newx = x_train) %>% data.frame() %>%
rename(Predicted=1) %>% cbind(temp) %>%
mutate(Points=log(Points)) %>%
mutate(Predicted=log(Predicted)) %>%
select(Player, Points, Predicted) %>%
arrange(-Points) %>%
mutate(row=row_number())
plot <- ggplot(one, aes(x=row, y=Points, color="Observed Point totals")) +
geom_point() +
geom_point(aes(y=Predicted, color="Predicted point totals")) +
geom_smooth(aes(y=Predicted, color="Smoothed best fit - Training")) +
geom_smooth(aes(y=Points, color="Smoothed best fit - Observed")) +
theme(axis.text.x = element_blank(),
legend.title = element_blank()) +
xlab("Player") + ylab("Log Points") +
ggtitle("Lowess curve: Validation of defenders ridge regression model, Training model")
plot
temp <- test_data %>% select(Player, Points)
one <- predict(ridge_model, newx = x_test) %>% data.frame() %>%
rename(Predicted=1) %>% cbind(temp) %>%
mutate(Points=log(Points)) %>%
mutate(Predicted=log(Predicted)) %>%
select(Player, Points, Predicted) %>%
arrange(-Points) %>%
mutate(row=row_number())
plot <- ggplot(two, aes(x=row, y=Points, color="Observed Point totals")) +
geom_point() +
geom_point(aes(y=Predicted, color="Predicted point totals")) +
geom_smooth(aes(y=Predicted, color="Smoothed best fit - Testing")) +
geom_smooth(aes(y=Points, color="Smoothed best fit - Observed")) +
theme(axis.text.x = element_blank(),
legend.title = element_blank()) +
xlab("Player") + ylab("Log Points") +
ggtitle("Lowess curve: Validation of defenders ridge regression model, Testing model")
plot
mid <- trends %>% ungroup() %>% filter(Position=="MID") %>%
select(all_of(c("Player", "Points")), all_of(m_rows)) %>%
mutate_all(~ ifelse(is.na(.),0,.))
one <- sample(seq_len(nrow(mid)), size=round(0.8*nrow(mid)), replace = F)
two <- setdiff(seq_len(nrow(mid)), one)
x_train <- mid[one, ] %>% select(-Player)
x_test <- mid[two, ]
temp <- x_test %>% select(Player)
mid_xtest <- x_test %>% select(-Player)
temp <- mid[one, ] %>% data.frame() %>% select(Player, Points)
one <- predict(ols_mid, newdata = x_train) %>% data.frame() %>%
rename(Predicted=1) %>% cbind(temp) %>%
mutate(Points=log(Points)) %>% mutate(Predicted=log(Predicted)) %>%
arrange(Player) %>%
mutate(row=row_number())
plot <- ggplot(one, aes(x=row, y=Points, color="Observed point totals")) +
geom_point() +
geom_point(aes(y=Predicted, color="Predicted point totals")) +
geom_smooth(aes(y=Predicted, color="Smoothed best fit - Training")) +
geom_smooth(aes(y=Points, color="Smoothed best fit - Observed")) +
theme(axis.text.x = element_blank(),
legend.title = element_blank()) +
xlab("Player") + ylab("Log Points") +
ggtitle("Lowess curve: Validation of midfielders OLS regression model, Training model")
plot
temp <- mid[two, ] %>% data.frame() %>% select(Player, Points)
one <- predict(ols_mid, newdata = x_test) %>% data.frame() %>%
rename(Predicted=1) %>% cbind(temp) %>%
mutate(Points=log(Points)) %>% mutate(Predicted=log(Predicted)) %>%
arrange(Player) %>%
mutate(row=row_number())
plot <- ggplot(one, aes(x=row, y=Points, color="Observed point totals")) +
geom_point() +
geom_point(aes(y=Predicted, color="Predicted point totals")) +
geom_smooth(aes(y=Predicted, color="Smoothed best fit - Testing")) +
geom_smooth(aes(y=Points, color="Smoothed best fit - Observed")) +
theme(axis.text.x = element_blank(),
legend.title = element_blank()) +
xlab("Player") + ylab("Log Points") +
ggtitle("Lowess curve: Validation of midfielders OLS regression model, Testing model")
plot
mid <- trends %>% ungroup() %>% filter(Position=="MID") %>%
select(all_of(c("Player", "Points")), all_of(m_rows)) %>%
mutate_all(~ ifelse(is.na(.),0,.))
one <- sample(seq_len(nrow(mid)), size=round(0.8*nrow(mid)), replace = F)
two <- setdiff(seq_len(nrow(mid)), one)
x_train <- mid[one, ] %>% select(-Player)
x_test <- mid[two, ]
temp <- x_test %>% select(Player)
mid_xtest <- x_test %>% select(-Player)
temp <- mid[one, ] %>% data.frame() %>% select(Player, Points)
one <- predict(ols_mid, newdata = x_train) %>% data.frame() %>%
rename(Predicted=1) %>% cbind(temp) %>%
mutate(Points=log(Points)) %>% mutate(Predicted=log(Predicted)) %>%
arrange(-Points) %>%
mutate(row=row_number())
plot <- ggplot(one, aes(x=row, y=Points, color="Observed point totals")) +
geom_point() +
geom_point(aes(y=Predicted, color="Predicted point totals")) +
geom_smooth(aes(y=Predicted, color="Smoothed best fit - Training")) +
geom_smooth(aes(y=Points, color="Smoothed best fit - Observed")) +
theme(axis.text.x = element_blank(),
legend.title = element_blank()) +
xlab("Player") + ylab("Log Points") +
ggtitle("Lowess curve: Validation of midfielders OLS regression model, Training model")
plot
temp <- mid[two, ] %>% data.frame() %>% select(Player, Points)
one <- predict(ols_mid, newdata = x_test) %>% data.frame() %>%
rename(Predicted=1) %>% cbind(temp) %>%
mutate(Points=log(Points)) %>% mutate(Predicted=log(Predicted)) %>%
arrange(-Points) %>%
mutate(row=row_number())
plot <- ggplot(one, aes(x=row, y=Points, color="Observed point totals")) +
geom_point() +
geom_point(aes(y=Predicted, color="Predicted point totals")) +
geom_smooth(aes(y=Predicted, color="Smoothed best fit - Testing")) +
geom_smooth(aes(y=Points, color="Smoothed best fit - Observed")) +
theme(axis.text.x = element_blank(),
legend.title = element_blank()) +
xlab("Player") + ylab("Log Points") +
ggtitle("Lowess curve: Validation of midfielders OLS regression model, Testing model")
plot
set.seed(123)
gk <- trends2 %>% ungroup() %>%
select(all_of(c("Player", "Points")), all_of(gk_rows)) %>%
mutate_all(~ ifelse(is.na(.),0,.))
train_index <- sample(1:nrow(gk), nrow(gk) * 0.8)
train_data <- gk[train_index, ]
x_train <- train_data %>% select(-c("Player"))
y_train <- train_data %>% select(Points) %>% data.matrix()
test_data <- gk[-train_index, ]
x_test <- test_data %>% select(-c("Player")) %>% data.matrix()
y_test <- test_data %>% select(Points) %>% data.matrix()
#dim(train_data)
#dim(test_data)
tr_control <- trainControl(method = "repeatedcv", number = 10, repeats=3, search = "random")
tunegrid <- expand.grid(.mtry=41)
rf_model <- train(Points~., data = x_train, method = "rf", tuneGrid=tunegrid,
trControl=tr_control, importance=T, nodesize=14, ntree=200,
maxnodes=12)
temp <- train_data %>% select(Player, Points)
one <- predict(rf_model, x_train) %>% data.frame() %>%
rename(Predicted=1) %>% cbind(temp) %>%
mutate(Points=log(Points)) %>% mutate(Predicted=log(Predicted)) %>%
arrange(-Points) %>%
mutate(row=row_number())
plot <- ggplot(one, aes(x=row, y=Points, color="Observed point totals")) +
geom_point() +
geom_point(aes(y=Predicted, color="Predicted point totals")) +
geom_smooth(aes(y=Predicted, color="Smoothed best fit - Training")) +
geom_smooth(aes(y=Points, color="Smoothed best fit - Observed")) +
theme(axis.text.x = element_blank(),
legend.title = element_blank()) +
xlab("Player") + ylab("Log Points") +
ggtitle("Lowess curve: Validation of goalkeepers random forest model, Training model")
plot
temp <- test_data %>% select(Player, Points)
one <- predict(rf_model, x_test) %>% data.frame() %>%
rename(Predicted=1) %>% cbind(temp) %>%
mutate(Points=log(Points)) %>% mutate(Predicted=log(Predicted)) %>%
arrange(-Points) %>%
mutate(row=row_number())
plot <- ggplot(one, aes(x=row, y=Points, color="Observed point totals")) +
geom_point() +
geom_point(aes(y=Predicted, color="Predicted point totals")) +
geom_smooth(aes(y=Predicted, color="Smoothed best fit - Testing")) +
geom_smooth(aes(y=Points, color="Smoothed best fit - Observed")) +
theme(axis.text.x = element_blank(),
legend.title = element_blank()) +
xlab("Player") + ylab("Log Points") +
ggtitle("Lowess curve: Validation of goalkeepers random forest model, Testing model")
plot
